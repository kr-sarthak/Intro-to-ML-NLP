{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539afb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "import accelerate \n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fa6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbb4ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# âœ… Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8fa52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Load tokenizer and dataset\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT2 has no pad_token\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266d615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Group text for training\n",
    "def group_texts(examples):\n",
    "    joined = sum(examples[\"input_ids\"], [])\n",
    "    chunks = [joined[i:i+128] for i in range(0, len(joined), 128)]\n",
    "    return {\"input_ids\": chunks, \"labels\": chunks}\n",
    "\n",
    "lm_dataset = tokenized.map(group_texts, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c691dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… Load model\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc56ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# âœ… Training config\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-wikitext2\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    fp16=True,  # Enable automatic mixed precision (faster training on GPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c482e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Trainer setup\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7ec0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408b70143ff24b0ab53407f88511f491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1846, 'grad_norm': 21.94734001159668, 'learning_rate': 4.974671823084046e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6294, 'grad_norm': 12.61223030090332, 'learning_rate': 4.947437224249687e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5844, 'grad_norm': 24.586185455322266, 'learning_rate': 4.920202625415328e-05, 'epoch': 0.02}\n",
      "{'loss': 3.6875, 'grad_norm': 7.776573181152344, 'learning_rate': 4.8929680265809685e-05, 'epoch': 0.02}\n",
      "{'loss': 3.565, 'grad_norm': 0.0, 'learning_rate': 4.865733427746609e-05, 'epoch': 0.03}\n",
      "{'loss': 3.58, 'grad_norm': 19.933956146240234, 'learning_rate': 4.83849882891225e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4654, 'grad_norm': 44.46742248535156, 'learning_rate': 4.811264230077891e-05, 'epoch': 0.04}\n",
      "{'loss': 3.6715, 'grad_norm': 22.65001678466797, 'learning_rate': 4.784029631243532e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4772, 'grad_norm': 7.614764213562012, 'learning_rate': 4.7567950324091725e-05, 'epoch': 0.05}\n",
      "{'loss': 3.6705, 'grad_norm': 6.97003698348999, 'learning_rate': 4.729560433574814e-05, 'epoch': 0.05}\n",
      "{'loss': 3.5278, 'grad_norm': 14.673432350158691, 'learning_rate': 4.7023258347404545e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4713, 'grad_norm': 8.249434471130371, 'learning_rate': 4.675091235906096e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5688, 'grad_norm': 8.357426643371582, 'learning_rate': 4.6478566370717366e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4605, 'grad_norm': 4.699357986450195, 'learning_rate': 4.620622038237377e-05, 'epoch': 0.08}\n",
      "{'loss': 3.5598, 'grad_norm': 4.9410295486450195, 'learning_rate': 4.593387439403018e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4339, 'grad_norm': 5.245522975921631, 'learning_rate': 4.5661528405686586e-05, 'epoch': 0.09}\n",
      "{'loss': 3.3033, 'grad_norm': 6.2699432373046875, 'learning_rate': 4.5389182417343e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4814, 'grad_norm': 4.788050174713135, 'learning_rate': 4.5116836428999406e-05, 'epoch': 0.1}\n",
      "{'loss': 3.4096, 'grad_norm': 9.735665321350098, 'learning_rate': 4.484449044065581e-05, 'epoch': 0.1}\n",
      "{'loss': 3.493, 'grad_norm': 4.436260223388672, 'learning_rate': 4.457214445231222e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4528, 'grad_norm': 0.0, 'learning_rate': 4.4299798463968626e-05, 'epoch': 0.11}\n",
      "{'loss': 3.4443, 'grad_norm': 16.68498420715332, 'learning_rate': 4.402745247562504e-05, 'epoch': 0.12}\n",
      "{'loss': 3.5096, 'grad_norm': 6.4266862869262695, 'learning_rate': 4.3755106487281446e-05, 'epoch': 0.13}\n",
      "{'loss': 3.4831, 'grad_norm': 5.472655773162842, 'learning_rate': 4.348276049893785e-05, 'epoch': 0.13}\n",
      "{'loss': 3.6265, 'grad_norm': 0.0, 'learning_rate': 4.321041451059426e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3641, 'grad_norm': 6.512332439422607, 'learning_rate': 4.2938068522250666e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4306, 'grad_norm': 4.701672077178955, 'learning_rate': 4.266572253390708e-05, 'epoch': 0.15}\n",
      "{'loss': 3.5118, 'grad_norm': 6.837732791900635, 'learning_rate': 4.239337654556349e-05, 'epoch': 0.15}\n",
      "{'loss': 3.4669, 'grad_norm': 5.343900680541992, 'learning_rate': 4.212103055721989e-05, 'epoch': 0.16}\n",
      "{'loss': 3.5117, 'grad_norm': 0.0, 'learning_rate': 4.18486845688763e-05, 'epoch': 0.16}\n",
      "{'loss': 3.4657, 'grad_norm': 6.701419830322266, 'learning_rate': 4.157633858053271e-05, 'epoch': 0.17}\n",
      "{'loss': 3.3878, 'grad_norm': 5.346504211425781, 'learning_rate': 4.130399259218912e-05, 'epoch': 0.17}\n",
      "{'loss': 3.313, 'grad_norm': 11.805712699890137, 'learning_rate': 4.103164660384553e-05, 'epoch': 0.18}\n",
      "{'loss': 3.2507, 'grad_norm': 0.0, 'learning_rate': 4.0759300615501934e-05, 'epoch': 0.19}\n",
      "{'loss': 3.2729, 'grad_norm': 0.0, 'learning_rate': 4.048695462715835e-05, 'epoch': 0.19}\n",
      "{'loss': 3.3947, 'grad_norm': 6.960669994354248, 'learning_rate': 4.0214608638814754e-05, 'epoch': 0.2}\n",
      "{'loss': 3.2331, 'grad_norm': 4.683627605438232, 'learning_rate': 3.994226265047116e-05, 'epoch': 0.2}\n",
      "{'loss': 3.3277, 'grad_norm': 14.384312629699707, 'learning_rate': 3.9669916662127574e-05, 'epoch': 0.21}\n",
      "{'loss': 3.1942, 'grad_norm': 6.59976053237915, 'learning_rate': 3.939757067378398e-05, 'epoch': 0.21}\n",
      "{'loss': 3.2489, 'grad_norm': 5.887033939361572, 'learning_rate': 3.912522468544039e-05, 'epoch': 0.22}\n",
      "{'loss': 3.2954, 'grad_norm': 4.162524223327637, 'learning_rate': 3.8852878697096794e-05, 'epoch': 0.22}\n",
      "{'loss': 3.2841, 'grad_norm': 19.535537719726562, 'learning_rate': 3.85805327087532e-05, 'epoch': 0.23}\n",
      "{'loss': 3.161, 'grad_norm': 5.441622257232666, 'learning_rate': 3.8308186720409614e-05, 'epoch': 0.23}\n",
      "{'loss': 3.2432, 'grad_norm': 5.85231351852417, 'learning_rate': 3.803584073206602e-05, 'epoch': 0.24}\n",
      "{'loss': 3.3816, 'grad_norm': 6.084383964538574, 'learning_rate': 3.776349474372243e-05, 'epoch': 0.25}\n",
      "{'loss': 3.3202, 'grad_norm': 0.0, 'learning_rate': 3.7491148755378835e-05, 'epoch': 0.25}\n",
      "{'loss': 3.3788, 'grad_norm': 5.480632781982422, 'learning_rate': 3.721880276703524e-05, 'epoch': 0.26}\n",
      "{'loss': 3.3229, 'grad_norm': 12.283140182495117, 'learning_rate': 3.6946456778691655e-05, 'epoch': 0.26}\n",
      "{'loss': 3.3431, 'grad_norm': 3.8978350162506104, 'learning_rate': 3.667411079034806e-05, 'epoch': 0.27}\n",
      "{'loss': 3.32, 'grad_norm': 21.517797470092773, 'learning_rate': 3.640176480200447e-05, 'epoch': 0.27}\n",
      "{'loss': 3.3649, 'grad_norm': 4.442751884460449, 'learning_rate': 3.6129418813660875e-05, 'epoch': 0.28}\n",
      "{'loss': 3.4118, 'grad_norm': 4.439850330352783, 'learning_rate': 3.585707282531728e-05, 'epoch': 0.28}\n",
      "{'loss': 3.2265, 'grad_norm': 0.0, 'learning_rate': 3.5584726836973695e-05, 'epoch': 0.29}\n",
      "{'loss': 3.279, 'grad_norm': 5.172057151794434, 'learning_rate': 3.53123808486301e-05, 'epoch': 0.29}\n",
      "{'loss': 3.4215, 'grad_norm': 5.790273189544678, 'learning_rate': 3.504003486028651e-05, 'epoch': 0.3}\n",
      "{'loss': 3.2732, 'grad_norm': 4.911988735198975, 'learning_rate': 3.477041233182635e-05, 'epoch': 0.31}\n",
      "{'loss': 3.2724, 'grad_norm': 9.009315490722656, 'learning_rate': 3.449806634348276e-05, 'epoch': 0.31}\n",
      "{'loss': 3.2336, 'grad_norm': 3.960883378982544, 'learning_rate': 3.422572035513917e-05, 'epoch': 0.32}\n",
      "{'loss': 3.237, 'grad_norm': 5.148577690124512, 'learning_rate': 3.395337436679558e-05, 'epoch': 0.32}\n",
      "{'loss': 2.9711, 'grad_norm': 6.166571617126465, 'learning_rate': 3.368102837845199e-05, 'epoch': 0.33}\n",
      "{'loss': 3.4086, 'grad_norm': 0.0, 'learning_rate': 3.34086823901084e-05, 'epoch': 0.33}\n",
      "{'loss': 3.4361, 'grad_norm': 8.991565704345703, 'learning_rate': 3.3136336401764805e-05, 'epoch': 0.34}\n",
      "{'loss': 3.2573, 'grad_norm': 0.0, 'learning_rate': 3.286399041342121e-05, 'epoch': 0.34}\n",
      "{'loss': 3.1688, 'grad_norm': 5.940476417541504, 'learning_rate': 3.2591644425077625e-05, 'epoch': 0.35}\n",
      "{'loss': 3.2088, 'grad_norm': 6.611778259277344, 'learning_rate': 3.231929843673403e-05, 'epoch': 0.35}\n",
      "{'loss': 3.0999, 'grad_norm': 4.021759033203125, 'learning_rate': 3.204695244839044e-05, 'epoch': 0.36}\n",
      "{'loss': 3.4281, 'grad_norm': 4.217374801635742, 'learning_rate': 3.1774606460046845e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2865, 'grad_norm': 4.970424652099609, 'learning_rate': 3.150226047170325e-05, 'epoch': 0.37}\n",
      "{'loss': 3.1532, 'grad_norm': 5.038504600524902, 'learning_rate': 3.1229914483359665e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2323, 'grad_norm': 0.0, 'learning_rate': 3.095756849501607e-05, 'epoch': 0.38}\n",
      "{'loss': 3.17, 'grad_norm': 4.194179534912109, 'learning_rate': 3.068522250667248e-05, 'epoch': 0.39}\n",
      "{'loss': 3.2216, 'grad_norm': 6.346665382385254, 'learning_rate': 3.0412876518328885e-05, 'epoch': 0.39}\n",
      "{'loss': 3.1327, 'grad_norm': 0.0, 'learning_rate': 3.0140530529985296e-05, 'epoch': 0.4}\n",
      "{'loss': 3.2296, 'grad_norm': 10.44612979888916, 'learning_rate': 2.9868184541641702e-05, 'epoch': 0.4}\n",
      "{'loss': 3.261, 'grad_norm': 14.19461727142334, 'learning_rate': 2.9595838553298112e-05, 'epoch': 0.41}\n",
      "{'loss': 3.3124, 'grad_norm': 16.23285484313965, 'learning_rate': 2.932349256495452e-05, 'epoch': 0.41}\n",
      "{'loss': 3.3186, 'grad_norm': 10.26976490020752, 'learning_rate': 2.9051146576610926e-05, 'epoch': 0.42}\n",
      "{'loss': 3.317, 'grad_norm': 5.387280464172363, 'learning_rate': 2.8778800588267336e-05, 'epoch': 0.42}\n",
      "{'loss': 3.4804, 'grad_norm': 5.384703159332275, 'learning_rate': 2.8506454599923743e-05, 'epoch': 0.43}\n",
      "{'loss': 3.2333, 'grad_norm': 10.498672485351562, 'learning_rate': 2.8234108611580153e-05, 'epoch': 0.44}\n",
      "{'loss': 3.262, 'grad_norm': 5.917418003082275, 'learning_rate': 2.796176262323656e-05, 'epoch': 0.44}\n",
      "{'loss': 3.2553, 'grad_norm': 15.074814796447754, 'learning_rate': 2.7689416634892966e-05, 'epoch': 0.45}\n",
      "{'loss': 3.2522, 'grad_norm': 3.910435676574707, 'learning_rate': 2.7417070646549376e-05, 'epoch': 0.45}\n",
      "{'loss': 3.0999, 'grad_norm': 6.197473526000977, 'learning_rate': 2.7144724658205783e-05, 'epoch': 0.46}\n",
      "{'loss': 3.2032, 'grad_norm': 4.8705830574035645, 'learning_rate': 2.6872378669862193e-05, 'epoch': 0.46}\n",
      "{'loss': 3.3584, 'grad_norm': 5.999050617218018, 'learning_rate': 2.6600032681518607e-05, 'epoch': 0.47}\n",
      "{'loss': 3.1833, 'grad_norm': 5.452843189239502, 'learning_rate': 2.6327686693175013e-05, 'epoch': 0.47}\n",
      "{'loss': 3.2823, 'grad_norm': 0.0, 'learning_rate': 2.605534070483142e-05, 'epoch': 0.48}\n",
      "{'loss': 3.1842, 'grad_norm': 4.062875747680664, 'learning_rate': 2.578299471648783e-05, 'epoch': 0.48}\n",
      "{'loss': 3.3816, 'grad_norm': 12.864144325256348, 'learning_rate': 2.5510648728144237e-05, 'epoch': 0.49}\n",
      "{'loss': 3.3092, 'grad_norm': 8.26540756225586, 'learning_rate': 2.5238302739800647e-05, 'epoch': 0.5}\n",
      "{'loss': 3.3901, 'grad_norm': 3.746922254562378, 'learning_rate': 2.4965956751457054e-05, 'epoch': 0.5}\n",
      "{'loss': 3.2497, 'grad_norm': 0.0, 'learning_rate': 2.469361076311346e-05, 'epoch': 0.51}\n",
      "{'loss': 3.161, 'grad_norm': 5.853264331817627, 'learning_rate': 2.442126477476987e-05, 'epoch': 0.51}\n",
      "{'loss': 3.1862, 'grad_norm': 24.778854370117188, 'learning_rate': 2.4148918786426277e-05, 'epoch': 0.52}\n",
      "{'loss': 3.1078, 'grad_norm': 5.778880596160889, 'learning_rate': 2.3876572798082687e-05, 'epoch': 0.52}\n",
      "{'loss': 3.302, 'grad_norm': 5.207368850708008, 'learning_rate': 2.3604226809739094e-05, 'epoch': 0.53}\n",
      "{'loss': 3.0832, 'grad_norm': 0.0, 'learning_rate': 2.33318808213955e-05, 'epoch': 0.53}\n",
      "{'loss': 3.3651, 'grad_norm': 5.603517532348633, 'learning_rate': 2.305953483305191e-05, 'epoch': 0.54}\n",
      "{'loss': 3.2207, 'grad_norm': 4.626908779144287, 'learning_rate': 2.2787188844708318e-05, 'epoch': 0.54}\n",
      "{'loss': 2.9382, 'grad_norm': 5.592051029205322, 'learning_rate': 2.2514842856364728e-05, 'epoch': 0.55}\n",
      "{'loss': 3.1303, 'grad_norm': 5.774465560913086, 'learning_rate': 2.2242496868021134e-05, 'epoch': 0.56}\n",
      "{'loss': 3.1396, 'grad_norm': 4.704346656799316, 'learning_rate': 2.197015087967754e-05, 'epoch': 0.56}\n",
      "{'loss': 3.1969, 'grad_norm': 0.0, 'learning_rate': 2.1700528351217387e-05, 'epoch': 0.57}\n",
      "{'loss': 3.1895, 'grad_norm': 5.880142688751221, 'learning_rate': 2.1428182362873797e-05, 'epoch': 0.57}\n",
      "{'loss': 3.0251, 'grad_norm': 4.717896461486816, 'learning_rate': 2.1155836374530204e-05, 'epoch': 0.58}\n",
      "{'loss': 3.175, 'grad_norm': 5.4701247215271, 'learning_rate': 2.0883490386186614e-05, 'epoch': 0.58}\n",
      "{'loss': 3.2655, 'grad_norm': 3.928865671157837, 'learning_rate': 2.061114439784302e-05, 'epoch': 0.59}\n",
      "{'loss': 3.2109, 'grad_norm': 10.151267051696777, 'learning_rate': 2.033879840949943e-05, 'epoch': 0.59}\n",
      "{'loss': 2.9999, 'grad_norm': 5.189733505249023, 'learning_rate': 2.0066452421155837e-05, 'epoch': 0.6}\n",
      "{'loss': 3.2064, 'grad_norm': 0.0, 'learning_rate': 1.9794106432812244e-05, 'epoch': 0.6}\n",
      "{'loss': 3.2403, 'grad_norm': 5.203189849853516, 'learning_rate': 1.9521760444468654e-05, 'epoch': 0.61}\n",
      "{'loss': 3.2702, 'grad_norm': 3.8499131202697754, 'learning_rate': 1.924941445612506e-05, 'epoch': 0.62}\n",
      "{'loss': 3.0832, 'grad_norm': 5.023043155670166, 'learning_rate': 1.897706846778147e-05, 'epoch': 0.62}\n",
      "{'loss': 3.1328, 'grad_norm': 0.0, 'learning_rate': 1.8704722479437878e-05, 'epoch': 0.63}\n",
      "{'loss': 3.0911, 'grad_norm': 5.281312942504883, 'learning_rate': 1.8432376491094284e-05, 'epoch': 0.63}\n",
      "{'loss': 3.0079, 'grad_norm': 6.5611419677734375, 'learning_rate': 1.8160030502750698e-05, 'epoch': 0.64}\n",
      "{'loss': 3.1559, 'grad_norm': 4.635769367218018, 'learning_rate': 1.7887684514407105e-05, 'epoch': 0.64}\n",
      "{'loss': 3.2418, 'grad_norm': 4.915926933288574, 'learning_rate': 1.761533852606351e-05, 'epoch': 0.65}\n",
      "{'loss': 3.002, 'grad_norm': 7.27363920211792, 'learning_rate': 1.734299253771992e-05, 'epoch': 0.65}\n",
      "{'loss': 3.1988, 'grad_norm': 26.69104766845703, 'learning_rate': 1.7070646549376328e-05, 'epoch': 0.66}\n",
      "{'loss': 3.2698, 'grad_norm': 0.0, 'learning_rate': 1.6798300561032738e-05, 'epoch': 0.66}\n",
      "{'loss': 3.165, 'grad_norm': 4.483056545257568, 'learning_rate': 1.652867803257258e-05, 'epoch': 0.67}\n",
      "{'loss': 3.1307, 'grad_norm': 6.341428279876709, 'learning_rate': 1.625633204422899e-05, 'epoch': 0.68}\n",
      "{'loss': 3.2818, 'grad_norm': 5.182738780975342, 'learning_rate': 1.5983986055885397e-05, 'epoch': 0.68}\n",
      "{'loss': 3.2049, 'grad_norm': 7.09559440612793, 'learning_rate': 1.5711640067541804e-05, 'epoch': 0.69}\n",
      "{'loss': 3.1888, 'grad_norm': 4.053673267364502, 'learning_rate': 1.5439294079198214e-05, 'epoch': 0.69}\n",
      "{'loss': 3.1678, 'grad_norm': 6.326351165771484, 'learning_rate': 1.516694809085462e-05, 'epoch': 0.7}\n",
      "{'loss': 3.2209, 'grad_norm': 0.0, 'learning_rate': 1.489460210251103e-05, 'epoch': 0.7}\n",
      "{'loss': 3.2225, 'grad_norm': 7.182440757751465, 'learning_rate': 1.4622256114167441e-05, 'epoch': 0.71}\n",
      "{'loss': 3.0044, 'grad_norm': 5.755993366241455, 'learning_rate': 1.4349910125823848e-05, 'epoch': 0.71}\n",
      "{'loss': 3.0701, 'grad_norm': 3.780022144317627, 'learning_rate': 1.4077564137480256e-05, 'epoch': 0.72}\n",
      "{'loss': 3.235, 'grad_norm': 3.8780179023742676, 'learning_rate': 1.3805218149136665e-05, 'epoch': 0.72}\n",
      "{'loss': 3.1725, 'grad_norm': 6.100778102874756, 'learning_rate': 1.3532872160793073e-05, 'epoch': 0.73}\n",
      "{'loss': 3.201, 'grad_norm': 5.386364936828613, 'learning_rate': 1.3260526172449481e-05, 'epoch': 0.74}\n",
      "{'loss': 3.2561, 'grad_norm': 3.9347381591796875, 'learning_rate': 1.2988180184105888e-05, 'epoch': 0.74}\n",
      "{'loss': 3.2183, 'grad_norm': 7.563599586486816, 'learning_rate': 1.2715834195762297e-05, 'epoch': 0.75}\n",
      "{'loss': 3.167, 'grad_norm': 3.7053074836730957, 'learning_rate': 1.2443488207418705e-05, 'epoch': 0.75}\n",
      "{'loss': 3.1084, 'grad_norm': 24.527503967285156, 'learning_rate': 1.2171142219075115e-05, 'epoch': 0.76}\n",
      "{'loss': 3.2246, 'grad_norm': 13.046313285827637, 'learning_rate': 1.1898796230731522e-05, 'epoch': 0.76}\n",
      "{'loss': 3.0573, 'grad_norm': 7.997371673583984, 'learning_rate': 1.162645024238793e-05, 'epoch': 0.77}\n",
      "{'loss': 3.0752, 'grad_norm': 5.58521032333374, 'learning_rate': 1.1354104254044339e-05, 'epoch': 0.77}\n",
      "{'loss': 3.0588, 'grad_norm': 8.704773902893066, 'learning_rate': 1.1081758265700747e-05, 'epoch': 0.78}\n",
      "{'loss': 3.3973, 'grad_norm': 6.32605504989624, 'learning_rate': 1.0809412277357155e-05, 'epoch': 0.78}\n",
      "{'loss': 3.0617, 'grad_norm': 21.516807556152344, 'learning_rate': 1.0537066289013562e-05, 'epoch': 0.79}\n",
      "{'loss': 3.0245, 'grad_norm': 5.6442437171936035, 'learning_rate': 1.0264720300669972e-05, 'epoch': 0.8}\n",
      "{'loss': 3.3204, 'grad_norm': 6.017210960388184, 'learning_rate': 9.99237431232638e-06, 'epoch': 0.8}\n",
      "{'loss': 3.083, 'grad_norm': 0.0, 'learning_rate': 9.720028323982789e-06, 'epoch': 0.81}\n",
      "{'loss': 3.0602, 'grad_norm': 4.552766799926758, 'learning_rate': 9.447682335639196e-06, 'epoch': 0.81}\n",
      "{'loss': 3.1327, 'grad_norm': 4.100655555725098, 'learning_rate': 9.175336347295604e-06, 'epoch': 0.82}\n",
      "{'loss': 2.9457, 'grad_norm': 0.0, 'learning_rate': 8.902990358952013e-06, 'epoch': 0.82}\n",
      "{'loss': 3.0965, 'grad_norm': 5.300483226776123, 'learning_rate': 8.630644370608423e-06, 'epoch': 0.83}\n",
      "{'loss': 3.2395, 'grad_norm': 19.5854549407959, 'learning_rate': 8.35829838226483e-06, 'epoch': 0.83}\n",
      "{'loss': 2.9499, 'grad_norm': 10.923232078552246, 'learning_rate': 8.085952393921238e-06, 'epoch': 0.84}\n",
      "{'loss': 3.2893, 'grad_norm': 5.036118030548096, 'learning_rate': 7.813606405577646e-06, 'epoch': 0.84}\n",
      "{'loss': 3.2457, 'grad_norm': 3.68215274810791, 'learning_rate': 7.541260417234054e-06, 'epoch': 0.85}\n",
      "{'loss': 3.1571, 'grad_norm': 6.7342071533203125, 'learning_rate': 7.268914428890462e-06, 'epoch': 0.86}\n",
      "{'loss': 3.1122, 'grad_norm': 4.555321216583252, 'learning_rate': 6.9965684405468715e-06, 'epoch': 0.86}\n",
      "{'loss': 3.0708, 'grad_norm': 6.1223626136779785, 'learning_rate': 6.72422245220328e-06, 'epoch': 0.87}\n",
      "{'loss': 3.2473, 'grad_norm': 3.85019850730896, 'learning_rate': 6.451876463859688e-06, 'epoch': 0.87}\n",
      "{'loss': 3.1829, 'grad_norm': 0.0, 'learning_rate': 6.182253935399531e-06, 'epoch': 0.88}\n",
      "{'loss': 3.1276, 'grad_norm': 5.881903171539307, 'learning_rate': 5.90990794705594e-06, 'epoch': 0.88}\n",
      "{'loss': 3.2285, 'grad_norm': 8.315399169921875, 'learning_rate': 5.637561958712348e-06, 'epoch': 0.89}\n",
      "{'loss': 3.04, 'grad_norm': 0.0, 'learning_rate': 5.365215970368757e-06, 'epoch': 0.89}\n",
      "{'loss': 3.0184, 'grad_norm': 5.843642234802246, 'learning_rate': 5.092869982025165e-06, 'epoch': 0.9}\n",
      "{'loss': 3.2058, 'grad_norm': 6.500776767730713, 'learning_rate': 4.8205239936815735e-06, 'epoch': 0.9}\n",
      "{'loss': 3.2255, 'grad_norm': 8.133624076843262, 'learning_rate': 4.548178005337982e-06, 'epoch': 0.91}\n",
      "{'loss': 3.0774, 'grad_norm': 0.0, 'learning_rate': 4.2758320169943895e-06, 'epoch': 0.92}\n",
      "{'loss': 3.0207, 'grad_norm': 5.522537708282471, 'learning_rate': 4.003486028650799e-06, 'epoch': 0.92}\n",
      "{'loss': 3.1885, 'grad_norm': 14.020939826965332, 'learning_rate': 3.7311400403072067e-06, 'epoch': 0.93}\n",
      "{'loss': 3.2541, 'grad_norm': 26.933683395385742, 'learning_rate': 3.4587940519636147e-06, 'epoch': 0.93}\n",
      "{'loss': 3.2665, 'grad_norm': 12.539899826049805, 'learning_rate': 3.1864480636200235e-06, 'epoch': 0.94}\n",
      "{'loss': 3.2015, 'grad_norm': 4.829955101013184, 'learning_rate': 2.9141020752764315e-06, 'epoch': 0.94}\n",
      "{'loss': 3.1866, 'grad_norm': 5.412079811096191, 'learning_rate': 2.6417560869328395e-06, 'epoch': 0.95}\n",
      "{'loss': 2.8016, 'grad_norm': 5.5784010887146, 'learning_rate': 2.369410098589248e-06, 'epoch': 0.95}\n",
      "{'loss': 2.976, 'grad_norm': 4.9098005294799805, 'learning_rate': 2.0970641102456563e-06, 'epoch': 0.96}\n",
      "{'loss': 3.0722, 'grad_norm': 0.0, 'learning_rate': 1.8247181219020643e-06, 'epoch': 0.96}\n",
      "{'loss': 3.0828, 'grad_norm': 0.0, 'learning_rate': 1.5523721335584727e-06, 'epoch': 0.97}\n",
      "{'loss': 2.9271, 'grad_norm': 3.8876516819000244, 'learning_rate': 1.2800261452148811e-06, 'epoch': 0.97}\n",
      "{'loss': 3.0308, 'grad_norm': 7.530019760131836, 'learning_rate': 1.0076801568712893e-06, 'epoch': 0.98}\n",
      "{'loss': 3.0458, 'grad_norm': 5.388713359832764, 'learning_rate': 7.353341685276976e-07, 'epoch': 0.99}\n",
      "{'loss': 2.9246, 'grad_norm': 4.433004379272461, 'learning_rate': 4.629881801841059e-07, 'epoch': 0.99}\n",
      "{'loss': 3.0302, 'grad_norm': 5.144527912139893, 'learning_rate': 1.9064219184051418e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6afc971d5fc442e87e66c525d6eecc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_runtime': 47.6033, 'eval_samples_per_second': 78.986, 'eval_steps_per_second': 39.493, 'epoch': 1.0}\n",
      "{'train_runtime': 2674.4426, 'train_samples_per_second': 13.729, 'train_steps_per_second': 6.865, 'train_loss': 3.2525149183898225, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18359, training_loss=3.2525149183898225, metrics={'train_runtime': 2674.4426, 'train_samples_per_second': 13.729, 'train_steps_per_second': 6.865, 'total_flos': 2398530207744000.0, 'train_loss': 3.2525149183898225, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5145ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daea3f92f0a842e4a8cc2e81662f19ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Perplexity: nan\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "perplexity = math.exp(eval_results[\"eval_loss\"])\n",
    "print(f\"ðŸ“Š Perplexity: {perplexity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee99e9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model saved to ./gpt2-wikitext2-final\n"
     ]
    }
   ],
   "source": [
    "# âœ… Save final model\n",
    "trainer.save_model(\"./gpt2-wikitext2-final\")\n",
    "tokenizer.save_pretrained(\"./gpt2-wikitext2-final\")\n",
    "print(\"Training complete. Model saved to ./gpt2-wikitext2-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3dfb479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Top-5 Accuracy: 20.00% on 100 samples\n"
     ]
    }
   ],
   "source": [
    "compute_top_k_accuracy(model, tokenizer, lm_dataset[\"validation\"], k=5, sample_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43cd1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "import numpy as np\n",
    "\n",
    "def compute_top_k_accuracy(model, tokenizer, dataset, k=5, sample_size=100):\n",
    "    model.eval()\n",
    "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, example in enumerate(dataset.select(range(sample_size))):\n",
    "        input_ids = torch.tensor(example['input_ids']).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the last token's logits\n",
    "        next_token_logits = logits[0, -1, :]\n",
    "        probs = softmax(next_token_logits, dim=0)\n",
    "        top_k = torch.topk(probs, k).indices.cpu().numpy()\n",
    "\n",
    "        # Check if the true next token is in the top-k predictions\n",
    "        if i + 1 < len(dataset):\n",
    "            target_token_id = dataset[i + 1]['input_ids'][0]  # crude next-token approximation\n",
    "            if target_token_id in top_k:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    top_k_acc = correct / total if total > 0 else 0\n",
    "    print(f\"ðŸŽ¯ Top-{k} Accuracy: {top_k_acc*100:.2f}% on {total} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "261b904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\gradio\\utils.py\", line 940, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\SHIVATEJA\\AppData\\Local\\Temp\\ipykernel_26428\\1983268133.py\", line 6, in predict_next_words\n",
      "    outputs = model.generate(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\generation\\utils.py\", line 1758, in generate\n",
      "    result = self._sample(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\generation\\utils.py\", line 2397, in _sample\n",
      "    outputs = self(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\accelerate\\utils\\operations.py\", line 818, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\accelerate\\utils\\operations.py\", line 806, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\amp\\autocast_mode.py\", line 44, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\", line 1302, in forward\n",
      "    transformer_outputs = self.transformer(\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\", line 1003, in forward\n",
      "    input_ids = input_ids.view(-1, input_shape[-1])\n",
      "RuntimeError: cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict_next_words(prompt, max_new_tokens=20, top_k=5):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_k=top_k,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=predict_next_words,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt\", placeholder=\"Enter a sentence like 'The future of AI is'\"),\n",
    "        gr.Slider(1, 50, value=20, step=1, label=\"Max New Tokens\"),\n",
    "        gr.Slider(1, 50, value=5, step=1, label=\"Top-k Sampling\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"ðŸ§  GPT-2 Next Word Predictor\"\n",
    ")\n",
    "\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
