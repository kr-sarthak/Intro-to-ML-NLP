{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqJmJjyZPILjIerT7C2OzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kr-sarthak/Intro-to-ML-NLP/blob/main/Assisngment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWiNjn9aPKfB",
        "outputId": "9c70e6e0-95a5-44cc-e9a0-f8411ae16e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array:\n",
            " [[18 45 14 19]\n",
            " [ 6 42 46  4]\n",
            " [ 3 13 11 39]\n",
            " [14 42  3 35]\n",
            " [28 16  5 31]] \n",
            "\n",
            "Anti-diagonal elements: [19, 46, 13, 14] \n",
            "\n",
            "Max in each row: [45 46 39 42 31] \n",
            "\n",
            "Elements <= mean ( 21.7 ): \n",
            " [18 14 19  6  4  3 13 11 14  3 16  5] \n",
            "\n",
            "Boundary traversal: [18, 45, 14, 19, 4, 39, 35, 31, 5, 16, 28, 14, 3, 6]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Random function\n",
        "arr = np.random.randint(1, 50, (5, 4))\n",
        "print(\"Array:\\n\", arr,\"\\n\")\n",
        "\n",
        "# Anti-diagonal elements (from top-right to bottom-left)\n",
        "anti_diag = [int(arr[i, -1 - i]) for i in range(min(arr.shape))]\n",
        "print(\"Anti-diagonal elements:\", anti_diag ,\"\\n\")\n",
        "\n",
        "# Max in each row\n",
        "max_rows = np.max(arr, axis=1)\n",
        "print(\"Max in each row:\", max_rows, \"\\n\")\n",
        "\n",
        "\n",
        "# Elements less than or equal to mean\n",
        "mean_val = np.mean(arr)\n",
        "filtered_arr = arr[arr <= mean_val]\n",
        "print(\"Elements <= mean (\", mean_val, \"):\", \"\\n\",filtered_arr,\"\\n\")\n",
        "\n",
        "# Boundary traversal function\n",
        "def numpy_boundary_traversal(matrix):\n",
        "    result = []\n",
        "    rows, cols = matrix.shape\n",
        "\n",
        "\n",
        "    result.extend(matrix[0]) # Top row\n",
        "\n",
        "    result.extend(matrix[1:rows-1, -1]) # Right column\n",
        "\n",
        "    result.extend(matrix[-1][::-1]) # Bottom row (reversed)\n",
        "\n",
        "    result.extend(matrix[rows-2:0:-1, 0]) # Left column (reversed)\n",
        "\n",
        "    return result\n",
        "\n",
        "print(\"Boundary traversal:\", [int(x) for x in numpy_boundary_traversal(arr)])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 1D array of float\n",
        "arr = np.random.uniform(0, 10, 20)\n",
        "arr = np.round(arr, 2)\n",
        "print(\"Rounded Array:\", arr,\"\\n\")\n",
        "\n",
        "# Print central Tendency\n",
        "print(\"Min:\", np.min(arr))\n",
        "print(\"Max:\", np.max(arr))\n",
        "print(\"Median:\", np.median(arr),\"\\n\")\n",
        "\n",
        "# Replace elements < 5 with their squares\n",
        "arr_modified = np.where(arr < 5, np.round(arr**2, 2), arr)\n",
        "print(\"Modified Array:\", arr_modified,\"\\n\")\n",
        "\n",
        "# Alternate sort\n",
        "def numpy_alternate_sort(array):\n",
        "    sorted_arr = np.sort(array)\n",
        "    result = []\n",
        "    left, right = 0, len(array) - 1\n",
        "    toggle = True\n",
        "\n",
        "    while left <= right:\n",
        "        if toggle:\n",
        "            result.append(sorted_arr[left])\n",
        "            left += 1\n",
        "        else:\n",
        "            result.append(sorted_arr[right])\n",
        "            right -= 1\n",
        "        toggle = not toggle\n",
        "\n",
        "    return np.array(result)\n",
        "\n",
        "print(\"Alternate Sorted Array:\", numpy_alternate_sort(arr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-nRctA-SvjR",
        "outputId": "67b5facc-0fe8-437e-ab7e-63b0ae0576b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rounded Array: [1.05 2.16 1.61 2.52 8.27 2.81 4.76 3.52 7.4  8.09 6.69 0.17 0.47 9.25\n",
            " 8.52 0.69 4.14 7.33 7.07 9.1 ] \n",
            "\n",
            "Min: 0.17\n",
            "Max: 9.25\n",
            "Median: 4.449999999999999 \n",
            "\n",
            "Modified Array: [ 1.1   4.67  2.59  6.35  8.27  7.9  22.66 12.39  7.4   8.09  6.69  0.03\n",
            "  0.22  9.25  8.52  0.48 17.14  7.33  7.07  9.1 ] \n",
            "\n",
            "Alternate Sorted Array: [0.17 9.25 0.47 9.1  0.69 8.52 1.05 8.27 1.61 8.09 2.16 7.4  2.52 7.33\n",
            " 2.81 7.07 3.52 6.69 4.14 4.76]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Student names and subjects\n",
        "names = ['Abhi', 'Gagan', 'Lakshmi', 'Ras', 'Vishu', 'Shivteja', 'Molly', 'Dev', 'Kumar', 'Vengla']\n",
        "subjects = ['Maths', 'Pharmacology', 'CS', 'Phsycology', 'Physiology', 'Medicine', 'Chemistry', 'Physics', 'Biology', 'Mechanics']\n",
        "\n",
        "#Generate random marks (50–100) for each student and each subject\n",
        "marks = {subject: np.random.randint(50, 101, size=len(names)) for subject in subjects}\n",
        "df = pd.DataFrame(marks)\n",
        "df.insert(0, 'Name', names)\n",
        "\n",
        "#Compute total and scaled score (out of 100)\n",
        "df['Total'] = df[subjects].sum(axis=1)\n",
        "df['Scaled Score'] = (df['Total'] / (len(subjects) * 100)) * 100\n",
        "\n",
        "#Assign Grade based on scaled score\n",
        "def assign_final_grade(score):\n",
        "    if score >= 90:\n",
        "        return 'A'\n",
        "    elif score >= 80:\n",
        "        return 'B'\n",
        "    elif score >= 70:\n",
        "        return 'C'\n",
        "    elif score >= 60:\n",
        "        return 'D'\n",
        "    else:\n",
        "        return 'F'\n",
        "\n",
        "df['Grade'] = df['Scaled Score'].apply(assign_final_grade)\n",
        "\n",
        "#Sort by Score descending\n",
        "sorted_df = df.sort_values(by='Scaled Score', ascending=False)\n",
        "\n",
        "#Average score for each subject\n",
        "subject_avg = df[subjects].mean().round(2)\n",
        "\n",
        "#Function to return students with grade A or B\n",
        "def pandas_filter_pass(dataframe):\n",
        "    return dataframe[dataframe['Grade'].isin(['A', 'B'])]\n",
        "passed_df = pandas_filter_pass(df)\n",
        "\n",
        "#Save all results\n",
        "#Wide marks table with grades\n",
        "df_output = df[['Name'] + subjects + ['Total', 'Scaled Score', 'Grade']]\n",
        "df_output.to_csv(\"problem3_student_wise_marks.csv\", index=False)\n",
        "\n",
        "#Sorted by score\n",
        "sorted_df.to_csv(\"problem3_sorted_by_score.csv\", index=False)\n",
        "\n",
        "#Subject averages\n",
        "subject_avg.to_csv(\"problem3_subject_averages.csv\")\n",
        "\n",
        "#A/B grade filter\n",
        "passed_df.to_csv(\"problem3_passed_students.csv\", index=False)\n",
        "\n",
        "#Optional print summary\n",
        "print(\"3 .Student Data (10 Students × 10 Subjects):\\n\")\n",
        "print(df_output.to_string(index=False))\n",
        "\n",
        "print(\"\\nStudents Sorted by Scaled Score:\\n\")\n",
        "print(sorted_df[['Name', 'Scaled Score', 'Grade']].to_string(index=False))\n",
        "\n",
        "print(\"\\nSubject-wise Average Scores:\\n\")\n",
        "print(subject_avg)\n",
        "\n",
        "print(\"\\nStudents with Grade A or B:\\n\")\n",
        "print(passed_df[['Name', 'Scaled Score', 'Grade']].to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUi9hUTIgDFs",
        "outputId": "89bee88d-d0e1-489e-b8f7-7847d38d281e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 .Student Data (10 Students × 10 Subjects):\n",
            "\n",
            "    Name  Maths  Pharmacology  CS  Phsycology  Physiology  Medicine  Chemistry  Physics  Biology  Mechanics  Total  Scaled Score Grade\n",
            "    Abhi     60            66  66          86          56        94         84       82       59         53    706          70.6     C\n",
            "   Gagan     54            61  71          50          64        64         82       64       76         75    661          66.1     D\n",
            " Lakshmi     68           100  69          64          54        75         74       96       51         72    723          72.3     C\n",
            "     Ras     60            77  84          72          75        91         57       67       59         93    735          73.5     C\n",
            "   Vishu     83            69  71          51          52        65         77       85       86         82    721          72.1     C\n",
            "Shivteja     82            70  97          84          94        87         87       52       88         83    824          82.4     B\n",
            "   Molly     90            91  79          71          88        83         80       60       79         99    820          82.0     B\n",
            "     Dev     86            68  91          55          52        59         67       50       76         61    665          66.5     D\n",
            "   Kumar     72            67  78          55          95        61         53       67       69         75    692          69.2     D\n",
            "  Vengla     63            63  60          83          77        57         73       99       69         66    710          71.0     C\n",
            "\n",
            "Students Sorted by Scaled Score:\n",
            "\n",
            "    Name  Scaled Score Grade\n",
            "Shivteja          82.4     B\n",
            "   Molly          82.0     B\n",
            "     Ras          73.5     C\n",
            " Lakshmi          72.3     C\n",
            "   Vishu          72.1     C\n",
            "  Vengla          71.0     C\n",
            "    Abhi          70.6     C\n",
            "   Kumar          69.2     D\n",
            "     Dev          66.5     D\n",
            "   Gagan          66.1     D\n",
            "\n",
            "Subject-wise Average Scores:\n",
            "\n",
            "Maths           71.8\n",
            "Pharmacology    73.2\n",
            "CS              76.6\n",
            "Phsycology      67.1\n",
            "Physiology      70.7\n",
            "Medicine        73.6\n",
            "Chemistry       73.4\n",
            "Physics         72.2\n",
            "Biology         71.2\n",
            "Mechanics       75.9\n",
            "dtype: float64\n",
            "\n",
            "Students with Grade A or B:\n",
            "\n",
            "    Name  Scaled Score Grade\n",
            "Shivteja          82.4     B\n",
            "   Molly          82.0     B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Positive Reviews\n",
        "positive_reviews = [\n",
        "    \"Absolutely loved the storyline and performances!\",\n",
        "    \"An emotional rollercoaster — in the best way!\",\n",
        "    \"The cinematography and music were breathtaking.\",\n",
        "    \"Brilliant acting and an unforgettable script.\",\n",
        "    \"One of the best movies I've seen in years.\",\n",
        "    \"A beautifully crafted film with a powerful message.\",\n",
        "    \"Outstanding direction and top-notch editing.\",\n",
        "    \"It kept me engaged from start to finish.\",\n",
        "    \"A masterpiece — pure cinema magic.\",\n",
        "    \"Spectacular visuals and strong character development.\"\n",
        "]\n",
        "\n",
        "# Negative Reviews\n",
        "negative_reviews = [\n",
        "    \"The plot was weak and painfully slow.\",\n",
        "    \"Terrible acting ruined an already bad script.\",\n",
        "    \"I couldn’t finish it — a total waste of time.\",\n",
        "    \"Predictable storyline and flat characters.\",\n",
        "    \"Boring and uninspired. I expected more.\",\n",
        "    \"Disappointing from such a well-known director.\",\n",
        "    \"The dialogues were cringe-worthy.\",\n",
        "    \"Overhyped and underdelivered.\",\n",
        "    \"Nothing made sense, and it dragged on forever.\",\n",
        "    \"It tried to be deep but ended up confusing and dull.\"\n",
        "]\n",
        "\n",
        "# Combine and label\n",
        "positive_reviews = positive_reviews * 5  # 10 × 5 = 50\n",
        "negative_reviews = negative_reviews * 5  # 10 × 5 = 50\n",
        "reviews = positive_reviews + negative_reviews\n",
        "sentiments = ['positive'] * len(positive_reviews) + ['negative'] * len(negative_reviews)\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'Review': reviews, 'Sentiment': sentiments})\n",
        "\n",
        "# Vectorize using CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=500, stop_words='english')\n",
        "X = vectorizer.fit_transform(df['Review'])\n",
        "y = df['Sentiment']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Prediction function\n",
        "def predict_review_sentiment(model, vectorizer, review):\n",
        "    review_vec = vectorizer.transform([review])\n",
        "    return model.predict(review_vec)[0]\n",
        "\n",
        "# Test the function\n",
        "test_review = \"I really enjoyed the acting and visuals.\"\n",
        "print(\"Review:\", test_review)\n",
        "print(\"Predicted Sentiment:\", predict_review_sentiment(model, vectorizer, test_review))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNeP7iNGorpb",
        "outputId": "d4c98a17-0d00-42c7-8949-6d317a4ff50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 1.0\n",
            "Review: I really enjoyed the acting and visuals.\n",
            "Predicted Sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Positive product review templates\n",
        "positive_templates = [\n",
        "    \"Absolutely love this product!\",\n",
        "    \"Exceeded my expectations — highly recommended.\",\n",
        "    \"Build quality is excellent.\",\n",
        "    \"Very effective and easy to use.\",\n",
        "    \"Fantastic performance for the price.\",\n",
        "    \"Reliable and well-designed.\",\n",
        "    \"Customer service was top-notch.\",\n",
        "    \"Fast delivery and great packaging.\",\n",
        "    \"The features are exactly what I needed.\",\n",
        "    \"Best purchase I've made this year!\"\n",
        "]\n",
        "\n",
        "# Negative product review templates\n",
        "negative_templates = [\n",
        "    \"Terrible experience, not worth the money.\",\n",
        "    \"Completely stopped working after a week.\",\n",
        "    \"The product was damaged when delivered.\",\n",
        "    \"Very poor quality materials used.\",\n",
        "    \"It did not match the description.\",\n",
        "    \"Not satisfied — it feels cheap and unreliable.\",\n",
        "    \"Customer service was unhelpful.\",\n",
        "    \"Too expensive for the value it offers.\",\n",
        "    \"Instructions were unclear and confusing.\",\n",
        "    \"Waste of money — would not recommend.\"\n",
        "]\n",
        "\n",
        "# Generate 50 positive and 50 negative reviews\n",
        "positive_reviews = random.choices(positive_templates, k=50)\n",
        "negative_reviews = random.choices(negative_templates, k=50)\n",
        "\n",
        "reviews = positive_reviews + negative_reviews\n",
        "labels = ['good'] * 50 + ['bad'] * 50\n",
        "\n",
        "# Shuffle the dataset\n",
        "data = list(zip(reviews, labels))\n",
        "random.shuffle(data)\n",
        "reviews, labels = zip(*data)\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"Review\": reviews,\n",
        "    \"Label\": labels\n",
        "})\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(max_features=300, stop_words='english')\n",
        "X = tfidf.fit_transform(df['Review'])\n",
        "y = df['Label']\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Logistic Regression Model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Text preprocessing and vectorization function\n",
        "def text_preprocess_vectorize(texts, vectorizer):\n",
        "    return vectorizer.transform(texts)\n",
        "\n",
        "# Test Prediction\n",
        "sample = \"This product is amazing and works perfectly!\"\n",
        "vectorized_sample = text_preprocess_vectorize([sample], tfidf)\n",
        "print(\"Sample Prediction:\", model.predict(vectorized_sample)[0])\n",
        "print(\"Vectorized shape:\", text_preprocess_vectorize([\"This product is amazing and works perfectly!\"], tfidf_vectorizer).shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO5xowb1pDYb",
        "outputId": "93c90486-a533-4bc2-d6d2-b96120784222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad       1.00      1.00      1.00        13\n",
            "        good       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        25\n",
            "   macro avg       1.00      1.00      1.00        25\n",
            "weighted avg       1.00      1.00      1.00        25\n",
            "\n",
            "Sample Prediction: good\n",
            "Vectorized shape: (1, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jr74IEUWwXq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}